{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cf9657",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ec877bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import av\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from transformers import AutoImageProcessor, VideoMAEModel\n",
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74704c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db1b1672",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_processor = AutoImageProcessor.from_pretrained(\"MCG-NJU/videomae-base\")\n",
    "#model = VideoMAEModel.from_pretrained(\"MCG-NJU/videomae-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74624e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'streams'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 48\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# sample 16 frames\u001b[39;00m\n\u001b[0;32m     47\u001b[0m container \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(container)\n\u001b[1;32m---> 48\u001b[0m indices \u001b[38;5;241m=\u001b[39m sample_frame_indices(clip_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, frame_sample_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, seg_len\u001b[38;5;241m=\u001b[39m\u001b[43mcontainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstreams\u001b[49m\u001b[38;5;241m.\u001b[39mvideo[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mframes)\n\u001b[0;32m     49\u001b[0m video \u001b[38;5;241m=\u001b[39m read_video_pyav(container, indices)\n\u001b[0;32m     51\u001b[0m image_processor \u001b[38;5;241m=\u001b[39m AutoImageProcessor\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMCG-NJU/videomae-base\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'streams'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "def read_video_pyav(container, indices):\n",
    "    frames = []\n",
    "    container.seek(0)\n",
    "    start_index = indices[0]\n",
    "    end_index = indices[-1]\n",
    "    for i, frame in enumerate(container.decode(video=0)):\n",
    "        if i > end_index:\n",
    "            break\n",
    "        if i >= start_index and i in indices:\n",
    "            frames.append(frame)\n",
    "    return np.stack([x.to_ndarray(format=\"rgb24\") for x in frames])\n",
    "\n",
    "\n",
    "def sample_frame_indices(clip_len, frame_sample_rate, seg_len):\n",
    "    converted_len = int(clip_len * frame_sample_rate)\n",
    "    end_idx = np.random.randint(converted_len, seg_len)\n",
    "    start_idx = end_idx - converted_len\n",
    "    indices = np.linspace(start_idx, end_idx, num=clip_len)\n",
    "    indices = np.clip(indices, start_idx, end_idx - 1).astype(np.int64)\n",
    "    return indices\n",
    "\n",
    "\n",
    "# Specify the root directory of the RAVDESS dataset\n",
    "dataset_root = r\"C:\\Users\\Admin\\Desktop\\F21RP\\Datasets\\Ravdess\\Videos\"\n",
    "\n",
    "# Get the list of folders in the dataset root directory\n",
    "folder_list = os.listdir(dataset_root)\n",
    "\n",
    "# Iterate over each folder\n",
    "for folder in folder_list:\n",
    "    folder_path = os.path.join(dataset_root, folder)\n",
    "    \n",
    "    # Check if the path is a directory\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "\n",
    "    # Iterate over each video file in the folder\n",
    "    for video_file in os.listdir(folder_path):\n",
    "        video_path = os.path.join(folder_path, video_file)\n",
    "        \n",
    "        container = os.path.isfile(video_path)\n",
    "        print(container)\n",
    "        # sample 16 frames\n",
    "        container = np.array(container)\n",
    "        indices = sample_frame_indices(clip_len=16, frame_sample_rate=1, seg_len=container.streams.video[0].frames)\n",
    "        video = read_video_pyav(container, indices)\n",
    "\n",
    "        image_processor = AutoImageProcessor.from_pretrained(\"MCG-NJU/videomae-base\")\n",
    "        model = VideoMAEModel.from_pretrained(\"MCG-NJU/videomae-base\")\n",
    "\n",
    "        # prepare video for the model\n",
    "        inputs = image_processor(list(video), return_tensors=\"pt\")\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        video_features = outputs.last_hidden_state\n",
    "\n",
    "        # Save the video features\n",
    "        save_path = os.path.join(dataset_root, folder, f\"{video_file}_features.pt\")\n",
    "        torch.save(video_features, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bac22e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
